{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Walk 2D continuous\n",
    "\n",
    "base environment on https://github.com/nicknochnack/ReinforcementLearningCourse/blob/main/Project%203%20-%20Custom%20Environment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuous state space environment\n",
    "\n",
    "action space: BOX in two directions from -1 to 1\n",
    "\n",
    "state space: box with shape(2,1)?\n",
    "\n",
    "goal reached when distance closer than 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([[0. 0.]\n",
      " [0. 0.]], [[10. 10.]\n",
      " [10. 10.]], (2, 2), float32)\n",
      "<class 'gym.spaces.box.Box'>\n",
      "[[9.209576 8.657924]\n",
      " [9.450312 8.482261]]\n",
      "<class 'numpy.ndarray'>\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "test_box = Box(low=0.0, high=10.0, shape=(2,2))\n",
    "print(test_box)\n",
    "print(type(test_box))\n",
    "print(test_box.sample())\n",
    "print(type(test_box.sample()))\n",
    "print(test_box.sample().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.822255   0.28385028]\n",
      " [6.005751   6.436809  ]]\n",
      "<class 'numpy.ndarray'>\n",
      "[3.48290359 3.23671321]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "state = np.ndarray(shape=(2,2), dtype=np.float32)\n",
    "print(state)\n",
    "print(type(state))\n",
    "state = np.random.uniform(0.0, 10.0, 2)\n",
    "print(state)\n",
    "print(type(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.62057846 5.51020763]\n",
      " [1.08893779 7.11932847]]\n",
      "[1.62057846 5.51020763]\n",
      "1.6946715466992928\n"
     ]
    }
   ],
   "source": [
    "state = np.random.uniform(0.0, 10.0, (2,2))\n",
    "print(state)\n",
    "print(state[0])\n",
    "distance = np.linalg.norm(state[0] - state[1])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11871922 0.05648993]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def out_of_bounds(state):\n",
    "    return not (0.0 <= state[0] <= 10.0 and 0.0 <= state[1] <= 10.0)\n",
    "\n",
    "position = np.random.uniform(-10.0, 10.0, (2,))\n",
    "print(position)\n",
    "print(out_of_bounds(position))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46764672 -0.6698517 ]\n",
      "[[5.969993  6.1932683]\n",
      " [7.053923  9.32972  ]]\n"
     ]
    }
   ],
   "source": [
    "class SimpleWalk2Dcont(Env):\n",
    "    \"\"\"simple walk environment in 1D with a continuous action and state space\"\"\"\n",
    "    def __init__(self):\n",
    "        self.action_space = Box(low=-1.0, high=1.0, shape=(2, ))\n",
    "        self.observation_space = Box(low=0.0, high=10.0, shape=(2, 2)) # 0 position, 1 goal\n",
    "        self.state = np.ndarray(shape=(2,2), dtype=np.float32)\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "        # update position\n",
    "        self.state[0] += action\n",
    "        \n",
    "        \n",
    "        position = self.state[0]\n",
    "        goal = self.state[1]\n",
    "        distance_to_goal = np.linalg.norm(state[0] - state[1])\n",
    "        \n",
    "        if out_of_bounds(position):\n",
    "            # went out of bounds\n",
    "            reward = -10.0\n",
    "            done = True\n",
    "        elif distance_to_goal < 1:\n",
    "            # reached goal\n",
    "            reward = 10.0\n",
    "            done = True\n",
    "        else:\n",
    "            # stepping is penalized\n",
    "            reward = -0.1\n",
    "            done = False\n",
    "        return self.state, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.random.uniform(0.0, 10.0, (2,2))\n",
    "        return self.state\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "    \n",
    "    def __out_of_bounds(state):\n",
    "        return not (0.0 <= state[0] <= 10.0 and 0.0 <= state[1] <= 10.0)\n",
    "    \n",
    "env = SimpleWalk2Dcont()\n",
    "\n",
    "print(env.action_space.sample())\n",
    "print(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-11.3\n",
      "Episode:2 Score:-12.3\n",
      "Episode:3 Score:6.399999999999999\n",
      "Episode:4 Score:-16.39999999999999\n",
      "Episode:5 Score:-10.0\n"
     ]
    }
   ],
   "source": [
    "env = SimpleWalk2Dcont()\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_9\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 15.8     |\n",
      "|    ep_rew_mean     | -11.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 436      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.6        |\n",
      "|    ep_rew_mean          | -12.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 438         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018371014 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.22        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x14f2fa38580>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.0, 2.6076809620810595)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aff22e454c7c7c2b414196c91e128cfd95ef64f890c08d8c85042177f44e9549"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('rl-test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
